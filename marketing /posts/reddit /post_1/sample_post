Trained an identity LoRA from a consented dataset to test realism using WAN 2.2

Hey everyone,
here’s a look at my realistic identity LoRA test built with a custom Docker + AI Toolkit setup on RunPod 
(WAN 2.2).The last image is the real person, the others are AI-generated using the trained LoRA.

Setup
Base model: WAN 2.2 (HighNoise + LowNoise combo)
Environment: Custom-baked Docker image

AI Toolkit (Next.js UI + JupyterLab)
LoRA training scripts and dependencies
Persistent /workspace volume for datasets and outputs

Gpu: RunPod A100 40GB instance
Frontend: ComfyUI with modular workflow design for stacking and testing multiple LoRAs 
Dataset: ~40 consented images of a real person, paired caption files with clean metadata and WAN-compatible preprocessing, overcomplicated the captions a bit, used a low step rate 3000, will def train it again with higher step rate and captions more focused on the Character than Envrioment


This was my first full LoRA workflow built entirely through GPT-5
it’s been a long time since I’ve had this much fun experimenting with new stuff, 
meanwhile RunPod just quietly drained my wallet in the background.
Planning next a “polish LoRA” to add fine-grained realism details like, Tattoos, Freckels and Birthmarks, the idea is to modularize realism.

Identity LoRA = likeness
Polish LoRA = surface detail / texture layer

(attached: a few SFW outdoor/indoor and portrait samples)

If anyone’s experimenting with WAN 2.2, LoRA stacking, or self-hosted training pods, I’d love to exchange workflows or compare results.

